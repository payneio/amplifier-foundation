# validate-bundle-repo.yaml
# Repository-Wide Bundle Validator Recipe v2.1.0
# Validates an entire bundle repository against structural requirements and conventions
#
# CHANGELOG:
# v2.1.0 - Added Python packaging validation phases
#        - Phase 0.5: packaging-check (pyproject.toml force-includes)
#        - Phase 0.7: build-check (dry-run pip wheel)
#        - Catches missing directories referenced in build config
#        - Prevents "renamed directory but forgot pyproject.toml" bugs
#
# v2.0.1 - Fixed undefined variable error when foundation not available
#        - quality-classification now handles skipped individual_validation
#        - Returns critical quality_level with appropriate messaging
#        - Downstream steps receive valid (if empty) data structure
#
# v2.0.0 - Major upgrade applying validate-agents v1.2.4 patterns
#        - Added explicit PASS thresholds (knows when to stop)
#        - Added deterministic quality classification (Phase 2.5)
#        - Added conditional LLM execution (skip when all bundles good)
#        - Added quick-approval path with claude-haiku
#        - Added "What is NOT an Issue" guidance to prevent nitpicking
#        - Added default values for skipped phases (Phase 2.75)
#        - Fixed JSON interpolation bug (json.loads instead of direct)
#        - Added optional agent validation integration placeholder
#
# v1.0.0 - Initial release
#        - Discovery, individual validation, composition analysis
#        - Convention compliance checking
#
# PASS THRESHOLDS (explicit criteria for "passing"):
# 1. All bundles load without errors (BundleRegistry succeeds)
# 2. Root bundle exists (if any bundles in repo) OR has behaviors/bundles dirs
# 3. No orphan agents (all agents referenced by some bundle)
# 4. No broken cross-bundle references (includes resolve)
# 5. Consistent namespace across bundles (if multiple bundles)
# 6. Python packaging builds successfully (if pyproject.toml present)
#
# QUALITY LEVELS:
# - good: All bundles load, no errors, no orphans, proper structure
# - polish: All load but has warnings (missing descriptions, conventions)
# - needs_work: Orphan agents, missing root, convention issues
# - critical: Any bundle fails to load OR Python package fails to build
#
# This recipe:
# 1. Discovers all bundles in a repo (root, behaviors, standalone, providers)
# 2. Validates Python packaging (pyproject.toml force-includes, build check)
# 3. Validates each bundle individually
# 4. Classifies overall quality (DETERMINISTIC - before LLM)
# 5. Quick-approves clean repos OR runs detailed analysis
# 6. Validates repo composition (conditional on quality)
# 7. Produces a comprehensive repo-level report
#
# Usage:
#   amplifier tool invoke recipes operation=execute \
#     recipe_path=foundation:recipes/validate-bundle-repo.yaml \
#     context='{"repo_path": "/path/to/my-bundle-repo"}'

name: validate-bundle-repo
description: |
  Validates an entire Amplifier bundle repository including:
  - Discovery of all bundle files (root, behaviors, standalone, providers)
  - Python packaging validation (pyproject.toml force-includes, build check)
  - Individual validation of each bundle via BundleRegistry
  - Deterministic quality classification with explicit PASS thresholds
  - Quick-approval path for clean repos (no unnecessary LLM analysis)
  - Repository composition analysis (do pieces fit together correctly?)
  - Convention compliance across the whole repo
  
  **v2.1.0 Improvements:**
  - Python packaging validation (catches pyproject.toml mismatches)
  - Build dry-run check (catches hatchling/setuptools errors early)
  
  **v2.0.0 Improvements:**
  - Deterministic quality classification before LLM analysis
  - Explicit PASS thresholds - no more "always finding something"
  - Quick-approval path for repos that meet all standards
  - LLM phases only run when genuinely needed
  - Optional agent validation integration
  
  For single bundle validation, use validate-bundle.yaml instead.
version: "2.1.0"
author: "Amplifier Foundation Team"
tags: ["bundle", "validation", "quality", "conventions", "repository", "packaging"]

context:
  repo_path: ""  # Required: Path to bundle repository root
  validate_agents: "false"  # Optional: Also run agent validation (true/false)

steps:
  # ============================================================================
  # PHASE 0: Environment Check
  # Verify amplifier_foundation is available
  # ============================================================================

  - id: "environment-check"
    type: "bash"
    command: |
      python3 << 'EOF'
      import json
      import sys

      results = {
          "phase": "environment",
          "foundation_available": False,
          "foundation_version": None,
          "python_version": sys.version,
          "errors": []
      }

      try:
          import amplifier_foundation
          results["foundation_available"] = True
          results["foundation_version"] = getattr(amplifier_foundation, "__version__", "unknown")
      except ImportError as e:
          results["errors"].append({
              "type": "import_error",
              "message": f"amplifier_foundation not importable: {e}",
              "suggestion": "Install via: pip install amplifier-foundation or run within an Amplifier session"
          })

      if not results["foundation_available"]:
          import subprocess
          try:
              subprocess.run(
                  [sys.executable, "-m", "pip", "install", "-q",
                   "git+https://github.com/microsoft/amplifier-foundation@main"],
                  check=True,
                  capture_output=True
              )
              import amplifier_foundation
              results["foundation_available"] = True
              results["foundation_version"] = getattr(amplifier_foundation, "__version__", "unknown")
              results["errors"] = []
              results["auto_installed"] = True
          except Exception as install_error:
              results["errors"].append({
                  "type": "install_error",
                  "message": f"Failed to auto-install: {install_error}"
              })

      print(json.dumps(results))
      EOF
    output: "env_check"
    parse_json: true
    timeout: 180

  # ============================================================================
  # PHASE 0.5: Packaging Consistency Check
  # Verify pyproject.toml force-includes reference existing directories
  # This catches the "renamed directory but forgot pyproject.toml" bug
  # ============================================================================

  - id: "packaging-check"
    type: "bash"
    command: |
      python3 << 'EOF'
      import json
      import sys
      from pathlib import Path

      repo_path = "{{repo_path}}"

      result = {
          "phase": "packaging_check",
          "has_pyproject": False,
          "force_includes_checked": 0,
          "errors": [],
          "warnings": []
      }

      pyproject_path = Path(repo_path) / "pyproject.toml"

      if not pyproject_path.exists():
          result["skipped"] = True
          result["passed"] = True
          result["reason"] = "No pyproject.toml (not a Python package bundle)"
          print(json.dumps(result))
          sys.exit(0)

      result["has_pyproject"] = True

      # Python 3.11+ has tomllib built-in
      try:
          import tomllib
      except ImportError:
          # Fallback for older Python
          try:
              import tomli as tomllib
          except ImportError:
              result["warnings"].append({
                  "type": "missing_toml_parser",
                  "message": "Cannot parse pyproject.toml - tomllib/tomli not available"
              })
              result["passed"] = True  # Can't check, don't fail
              print(json.dumps(result))
              sys.exit(0)

      try:
          with open(pyproject_path, "rb") as f:
              config = tomllib.load(f)
      except Exception as e:
          result["errors"].append({
              "type": "toml_parse_error",
              "message": f"Failed to parse pyproject.toml: {e}",
              "severity": "ERROR"
          })
          result["passed"] = False
          print(json.dumps(result))
          sys.exit(0)

      # Check hatchling force-includes
      force_includes = (config.get("tool", {})
                             .get("hatch", {})
                             .get("build", {})
                             .get("targets", {})
                             .get("wheel", {})
                             .get("force-include", {}))

      for source_path, dest_path in force_includes.items():
          result["force_includes_checked"] += 1
          full_path = Path(repo_path) / source_path

          if not full_path.exists():
              result["errors"].append({
                  "type": "missing_force_include",
                  "source": source_path,
                  "destination": dest_path,
                  "message": f"pyproject.toml force-include references non-existent path: {source_path}",
                  "severity": "CRITICAL",
                  "fix": f"Either create '{source_path}' or remove/update the force-include entry"
              })

      # Check setuptools package-data or data-files if present
      package_data = config.get("tool", {}).get("setuptools", {}).get("package-data", {})
      for package, patterns in package_data.items():
          for pattern in patterns:
              # Basic check - if it's a specific path (not a glob), verify it exists
              if "*" not in pattern and "?" not in pattern:
                  full_path = Path(repo_path) / pattern
                  if not full_path.exists():
                      result["warnings"].append({
                          "type": "missing_package_data",
                          "package": package,
                          "pattern": pattern,
                          "message": f"package-data references potentially missing path: {pattern}"
                      })

      result["passed"] = len(result["errors"]) == 0
      print(json.dumps(result))
      EOF
    output: "packaging_check"
    parse_json: true
    timeout: 30
    depends_on: ["environment-check"]

  # ============================================================================
  # PHASE 0.7: Build Dry-Run Check
  # Actually attempt a dry-run pip install to catch build issues
  # Only runs if pyproject.toml exists
  # ============================================================================

  - id: "build-check"
    type: "bash"
    condition: "{{packaging_check.has_pyproject}} == true"
    command: |
      python3 << 'EOF'
      import json
      import subprocess
      import sys
      import tempfile
      from pathlib import Path

      repo_path = "{{repo_path}}"

      result = {
          "phase": "build_check",
          "build_tested": False,
          "errors": [],
          "warnings": []
      }

      pyproject_path = Path(repo_path) / "pyproject.toml"
      if not pyproject_path.exists():
          result["skipped"] = True
          result["passed"] = True
          result["reason"] = "No pyproject.toml"
          print(json.dumps(result))
          sys.exit(0)

      # Try a dry-run build using pip wheel with --no-build-isolation for speed
      # This catches hatchling/setuptools build errors without actually installing
      try:
          # Create a temp directory for the wheel output
          with tempfile.TemporaryDirectory() as tmpdir:
              # Try pip wheel which does a full build check
              proc = subprocess.run(
                  [sys.executable, "-m", "pip", "wheel", "--no-deps", "--no-build-isolation",
                   "-w", tmpdir, repo_path],
                  capture_output=True,
                  text=True,
                  timeout=120,
                  cwd=repo_path
              )

              if proc.returncode != 0:
                  # Extract relevant error from output
                  error_output = proc.stderr or proc.stdout

                  # Look for common patterns
                  if "FileNotFoundError" in error_output or "No such file or directory" in error_output:
                      result["errors"].append({
                          "type": "build_missing_file",
                          "message": "Build failed due to missing file",
                          "details": error_output[-2000:],  # Last 2000 chars
                          "severity": "CRITICAL"
                      })
                  elif "force-include" in error_output.lower():
                      result["errors"].append({
                          "type": "build_force_include_error",
                          "message": "Build failed due to force-include configuration",
                          "details": error_output[-2000:],
                          "severity": "CRITICAL"
                      })
                  else:
                      result["errors"].append({
                          "type": "build_error",
                          "message": "Package build failed",
                          "details": error_output[-2000:],
                          "severity": "CRITICAL"
                      })
              else:
                  result["build_tested"] = True
                  result["build_success"] = True

      except subprocess.TimeoutExpired:
          result["warnings"].append({
              "type": "build_timeout",
              "message": "Build check timed out (120s) - may indicate complex build"
          })
      except FileNotFoundError:
          # pip not available in expected way
          result["warnings"].append({
              "type": "build_tools_unavailable",
              "message": "Could not run build check - pip not available"
          })
      except Exception as e:
          result["warnings"].append({
              "type": "build_check_error",
              "message": f"Build check encountered error: {e}"
          })

      result["passed"] = len(result["errors"]) == 0
      print(json.dumps(result))
      EOF
    output: "build_check"
    parse_json: true
    timeout: 180
    depends_on: ["packaging-check"]

  # Set default for build_check if packaging check skipped (no pyproject.toml)
  - id: "set-default-build-check"
    type: "bash"
    condition: "{{packaging_check.has_pyproject}} != true"
    command: |
      python3 << 'EOF'
      import json
      result = {
          "phase": "build_check",
          "skipped": True,
          "passed": True,
          "reason": "No pyproject.toml - not a Python package"
      }
      print(json.dumps(result))
      EOF
    output: "build_check"
    parse_json: true
    timeout: 10
    depends_on: ["packaging-check"]

  # ============================================================================
  # PHASE 1: Repository Discovery
  # Find all bundle files in the repository
  # ============================================================================

  - id: "repo-discovery"
    type: "bash"
    command: |
      python3 << 'EOF'
      import json
      from pathlib import Path

      def discover_bundles(repo_path: str) -> dict:
          """Discover all bundle files in a repository."""
          results = {
              "phase": "discovery",
              "repo_path": repo_path,
              "bundles_found": {
                  "root": [],
                  "behaviors": [],
                  "standalone": [],
                  "providers": [],
                  "agents": [],
                  "other": []
              },
              "total_count": 0,
              "repo_structure": {},
              "errors": []
          }

          path = Path(repo_path).resolve()

          if not path.exists():
              results["errors"].append({
                  "type": "path_error",
                  "message": f"Repository path does not exist: {repo_path}"
              })
              print(json.dumps(results))
              return results

          if not path.is_dir():
              results["errors"].append({
                  "type": "path_error",
                  "message": f"Path is not a directory: {repo_path}"
              })
              print(json.dumps(results))
              return results

          # Check for root bundle
          for name in ["bundle.md", "bundle.yaml"]:
              root_bundle = path / name
              if root_bundle.exists():
                  results["bundles_found"]["root"].append(str(root_bundle))

          # Scan conventional directories
          scan_dirs = {
              "behaviors": "behaviors",
              "standalone": "bundles",
              "providers": "providers",
              "agents": "agents"
          }

          for category, dir_name in scan_dirs.items():
              dir_path = path / dir_name
              if dir_path.exists() and dir_path.is_dir():
                  for item in dir_path.iterdir():
                      if item.is_file() and item.suffix in [".md", ".yaml", ".yml"]:
                          results["bundles_found"][category].append(str(item))
                      elif item.is_dir():
                          # Check for bundle inside subdirectory
                          for sub_name in ["bundle.md", "bundle.yaml"]:
                              sub_bundle = item / sub_name
                              if sub_bundle.exists():
                                  results["bundles_found"][category].append(str(sub_bundle))

          # Map repo structure
          results["repo_structure"] = {
              "has_root_bundle": len(results["bundles_found"]["root"]) > 0,
              "has_behaviors": len(results["bundles_found"]["behaviors"]) > 0,
              "has_standalone": len(results["bundles_found"]["standalone"]) > 0,
              "has_providers": len(results["bundles_found"]["providers"]) > 0,
              "has_agents": len(results["bundles_found"]["agents"]) > 0,
              "directories": [d.name for d in path.iterdir() if d.is_dir() and not d.name.startswith(".")]
          }

          # Count totals
          for category, bundles in results["bundles_found"].items():
              results["total_count"] += len(bundles)

          print(json.dumps(results))
          return results

      discover_bundles("{{repo_path}}")
      EOF
    output: "discovery_results"
    parse_json: true
    timeout: 60
    depends_on: ["packaging-check", "build-check", "set-default-build-check"]

  # ============================================================================
  # PHASE 2: Individual Bundle Validation
  # Validate each discovered bundle structurally
  # ============================================================================

  - id: "validate-all-bundles"
    type: "bash"
    command: |
      python3 << 'EOF'
      import asyncio
      import json
      import sys
      from pathlib import Path

      # FIX: Use json.loads() to properly handle JSON booleans (true/false vs True/False)
      env_check = json.loads('''{{env_check}}''')
      if not env_check.get("foundation_available"):
          print(json.dumps({
              "phase": "individual_validation",
              "skipped": True,
              "reason": "amplifier_foundation not available"
          }))
          sys.exit(0)

      from amplifier_foundation import BundleRegistry
      from amplifier_foundation.exceptions import (
          BundleLoadError,
          BundleNotFoundError,
          BundleDependencyError,
          BundleValidationError
      )

      # FIX: Use json.loads() for JSON boolean handling
      discovery = json.loads('''{{discovery_results}}''')
      
      async def validate_bundle(bundle_path: str, category: str) -> dict:
          """Validate a single bundle and return results."""
          result = {
              "path": bundle_path,
              "category": category,
              "passed": True,
              "name": None,
              "errors": [],
              "warnings": []
          }

          try:
              registry = BundleRegistry()
              path = Path(bundle_path).resolve()
              uri = f"file://{path}"

              bundle = await registry._load_single(
                  uri,
                  auto_register=True,
                  auto_include=False  # Don't follow includes for individual check
              )

              result["name"] = bundle.name
              result["version"] = bundle.version
              result["has_instruction"] = bool(bundle.instruction)
              result["includes_count"] = len(bundle.includes)
              result["agents_count"] = len(bundle.agents)
              result["has_description"] = bool(getattr(bundle, 'description', None))

              if not bundle.name:
                  result["warnings"].append("Missing bundle.name")
              
              # Check for description (quality indicator)
              if not getattr(bundle, 'description', None):
                  result["warnings"].append("Missing bundle description")

          except BundleDependencyError as e:
              result["passed"] = False
              result["errors"].append(f"Dependency error: {e}")
          except BundleLoadError as e:
              result["passed"] = False
              result["errors"].append(f"Load error: {e}")
          except Exception as e:
              result["passed"] = False
              result["errors"].append(f"{type(e).__name__}: {e}")

          return result

      async def validate_all():
          results = {
              "phase": "individual_validation",
              "skipped": False,
              "bundles": [],
              "summary": {
                  "total": 0,
                  "passed": 0,
                  "failed": 0,
                  "warnings": 0,
                  "by_category": {}
              }
          }

          all_bundles = []
          for category, paths in discovery.get("bundles_found", {}).items():
              for path in paths:
                  all_bundles.append((path, category))

          for bundle_path, category in all_bundles:
              result = await validate_bundle(bundle_path, category)
              results["bundles"].append(result)
              results["summary"]["total"] += 1
              
              if result["passed"]:
                  results["summary"]["passed"] += 1
              else:
                  results["summary"]["failed"] += 1
              
              if result.get("warnings"):
                  results["summary"]["warnings"] += len(result["warnings"])

              if category not in results["summary"]["by_category"]:
                  results["summary"]["by_category"][category] = {"passed": 0, "failed": 0, "warnings": 0}
              
              if result["passed"]:
                  results["summary"]["by_category"][category]["passed"] += 1
              else:
                  results["summary"]["by_category"][category]["failed"] += 1
              
              if result.get("warnings"):
                  results["summary"]["by_category"][category]["warnings"] += len(result["warnings"])

          print(json.dumps(results))

      asyncio.run(validate_all())
      EOF
    output: "individual_validation"
    parse_json: true
    timeout: 300
    on_error: "continue"
    depends_on: ["repo-discovery"]

  # ============================================================================
  # PHASE 2.5: Quality Classification (Deterministic)
  # Classify overall repo quality to determine if LLM analysis is needed
  # This is the key v2.0.0 addition - explicit PASS thresholds
  # Updated in v2.1.0 to include packaging errors
  # ============================================================================

  - id: "quality-classification"
    type: "bash"
    command: |
      python3 << 'EOF'
      import json
      import sys
      from pathlib import Path

      # Parse results as JSON
      individual = json.loads('''{{individual_validation}}''')
      discovery = json.loads('''{{discovery_results}}''')
      packaging = json.loads('''{{packaging_check}}''')
      
      # Handle build_check which may be from conditional step
      build_check_raw = '''{{build_check}}'''
      try:
          build = json.loads(build_check_raw)
      except (json.JSONDecodeError, ValueError):
          build = {"passed": True, "skipped": True, "reason": "build check output not available"}

      # Handle case where validation was skipped (e.g., foundation not available)
      if individual.get("skipped", False):
          result = {
              "phase": "quality_classification",
              "quality_level": "critical",
              "requires_llm_analysis": True,
              "skipped_reason": individual.get("reason", "validation skipped"),
              "bundles": [],
              "summary": {
                  "total": 0,
                  "good": 0,
                  "polish": 0,
                  "needs_work": 0,
                  "critical": 0
              },
              "structural_issues": [{
                  "type": "validation_skipped",
                  "message": individual.get("reason", "Individual bundle validation was skipped"),
                  "severity": "critical"
              }],
              "packaging_issues": [],
              "message": f"‚ö†Ô∏è Bundle validation could not run: {individual.get('reason', 'unknown reason')}"
          }
          print(json.dumps(result))
          sys.exit(0)

      # EXPLICIT PASS THRESHOLDS
      # A repository PASSES if ALL of these criteria are met:
      # 1. All bundles load without errors (BundleRegistry succeeds)
      # 2. Has proper structure (root bundle OR behaviors/bundles dirs)
      # 3. No orphan agents (if agents/ exists, they're referenced)
      # 4. Consistent namespace (not strictly enforced, but checked)
      # 5. Python packaging builds successfully (if pyproject.toml present)

      def classify_bundle(bundle: dict) -> dict:
          """Classify a single bundle's quality level."""
          has_errors = len(bundle.get("errors", [])) > 0
          has_warnings = len(bundle.get("warnings", [])) > 0
          has_description = bundle.get("has_description", False)
          
          if has_errors:
              quality = "critical"
              reason = f"Bundle failed to load: {bundle.get('errors', ['unknown'])[0]}"
          elif has_warnings:
              quality = "polish"
              reason = f"Has {len(bundle.get('warnings', []))} warnings"
          else:
              quality = "good"
              reason = "Loads successfully with no issues"
          
          return {
              "path": bundle.get("path"),
              "name": bundle.get("name"),
              "category": bundle.get("category"),
              "quality": quality,
              "reason": reason,
              "has_description": has_description,
              "error_count": len(bundle.get("errors", [])),
              "warning_count": len(bundle.get("warnings", []))
          }

      def classify_repo():
          results = {
              "phase": "classification",
              "bundles": [],
              "summary": {
                  "total": 0,
                  "good": 0,
                  "polish": 0,
                  "needs_work": 0,
                  "critical": 0
              },
              "quality_level": "good",
              "requires_llm_analysis": False,
              "structural_issues": [],
              "packaging_issues": []
          }
          
          # Classify each bundle
          for bundle in individual.get("bundles", []):
              classification = classify_bundle(bundle)
              results["bundles"].append(classification)
              results["summary"]["total"] += 1
              results["summary"][classification["quality"]] += 1
          
          # Check structural requirements
          repo_structure = discovery.get("repo_structure", {})
          has_root = repo_structure.get("has_root_bundle", False)
          has_behaviors = repo_structure.get("has_behaviors", False)
          has_standalone = repo_structure.get("has_standalone", False)
          has_agents = repo_structure.get("has_agents", False)
          
          # A valid bundle repo needs SOME entry point
          if not has_root and not has_behaviors and not has_standalone:
              results["structural_issues"].append({
                  "type": "no_entry_point",
                  "message": "No root bundle, behaviors/, or bundles/ directory found",
                  "severity": "needs_work"
              })
          
          # Check for orphan agents (agents/ exists but no behaviors reference them)
          if has_agents and not has_behaviors and not has_root:
              results["structural_issues"].append({
                  "type": "orphan_agents",
                  "message": "agents/ directory exists but no behaviors or root bundle to include them",
                  "severity": "needs_work"
              })
          
          # Check packaging errors (v2.1.0)
          if not packaging.get("passed", True):
              for error in packaging.get("errors", []):
                  results["packaging_issues"].append({
                      "type": error.get("type", "packaging_error"),
                      "message": error.get("message", "Unknown packaging error"),
                      "severity": "critical",
                      "fix": error.get("fix", "Check pyproject.toml configuration")
                  })
              results["summary"]["critical"] += 1
          
          # Check build errors (v2.1.0)
          if not build.get("passed", True):
              for error in build.get("errors", []):
                  results["packaging_issues"].append({
                      "type": error.get("type", "build_error"),
                      "message": error.get("message", "Unknown build error"),
                      "severity": "critical",
                      "details": error.get("details", "")[:500]  # Truncate long details
                  })
              results["summary"]["critical"] += 1
          
          # Determine overall quality level
          # Priority: critical > needs_work > polish > good
          if results["summary"]["critical"] > 0 or len(results["packaging_issues"]) > 0:
              results["quality_level"] = "critical"
              results["requires_llm_analysis"] = True
          elif results["summary"]["needs_work"] > 0 or len([i for i in results["structural_issues"] if i["severity"] == "needs_work"]) > 0:
              results["quality_level"] = "needs_work"
              results["requires_llm_analysis"] = True
          elif results["summary"]["polish"] > 0 or len(results["structural_issues"]) > 0:
              results["quality_level"] = "polish"
              # Polish-level issues may benefit from LLM review
              results["requires_llm_analysis"] = True
          else:
              results["quality_level"] = "good"
              # All bundles pass! No LLM analysis needed.
              results["requires_llm_analysis"] = False
          
          # Provide summary message
          total = results["summary"]["total"]
          good = results["summary"]["good"]
          pkg_issues = len(results["packaging_issues"])
          
          if results["quality_level"] == "good":
              results["message"] = f"‚úÖ All {total} bundles meet quality thresholds. No further analysis needed."
          else:
              not_good = total - good
              struct_issues = len(results["structural_issues"])
              if pkg_issues > 0:
                  results["message"] = f"üö® {pkg_issues} packaging issues, {not_good}/{total} bundles, and {struct_issues} structural issues need attention."
              else:
                  results["message"] = f"‚ö†Ô∏è {not_good}/{total} bundles and {struct_issues} structural issues need attention."
          
          print(json.dumps(results))

      classify_repo()
      EOF
    output: "quality_classification"
    parse_json: true
    timeout: 60
    depends_on: ["validate-all-bundles"]

  # ============================================================================
  # PHASE 2.75: Initialize Optional Outputs
  # Set default values for variables that may be skipped by conditional phases
  # This prevents undefined variable errors in Phase 5
  # ============================================================================

  - id: "initialize-optional-outputs"
    type: "bash"
    command: |
      python3 << 'EOF'
      import json
      
      # Initialize default values for conditional phase outputs
      # These will be overwritten if the corresponding phase runs
      defaults = {
          "approval_summary": "_Quick approval not performed - detailed LLM analysis was run instead._",
          "composition_analysis": "_Composition analysis not performed - all bundles met quality thresholds via deterministic checks._",
          "repo_conventions": "_Convention analysis not performed - all bundles met quality thresholds._"
      }
      
      print(json.dumps(defaults))
      EOF
    output: "optional_defaults"
    parse_json: true
    timeout: 30
    depends_on: ["quality-classification"]

  # Set individual default values (will be overwritten by conditional steps if they run)
  - id: "set-default-approval-summary"
    type: "bash"
    command: |
      echo "_Quick approval not performed - detailed LLM analysis was run instead._"
    output: "approval_summary"
    timeout: 10
    depends_on: ["initialize-optional-outputs"]

  - id: "set-default-composition-analysis"
    type: "bash"
    command: |
      echo "_Composition analysis not performed - all bundles met quality thresholds via deterministic checks._"
    output: "composition_analysis"
    timeout: 10
    depends_on: ["initialize-optional-outputs"]

  - id: "set-default-repo-conventions"
    type: "bash"
    command: |
      echo "_Convention analysis not performed - all bundles met quality thresholds._"
    output: "repo_conventions"
    timeout: 10
    depends_on: ["initialize-optional-outputs"]

  # ============================================================================
  # PHASE 3: Quick Approval (When All Bundles Pass)
  # Fast-track path for repos that meet all quality thresholds
  # Model: haiku - simple summary, no complex reasoning needed
  # ============================================================================

  - id: "quick-approval"
    agent: "foundation:zen-architect"
    mode: "REVIEW"
    provider: "anthropic"
    model: "claude-haiku"
    condition: "{{quality_classification.requires_llm_analysis}} == false"
    depends_on: ["set-default-approval-summary"]
    prompt: |
      All bundles in this repository meet quality thresholds. Provide a brief approval summary.

      **Repository Path:** {{repo_path}}

      **Quality Classification Results:**
      ```json
      {{quality_classification}}
      ```

      **Discovery Summary:**
      ```json
      {{discovery_results}}
      ```

      **Packaging Check:**
      ```json
      {{packaging_check}}
      ```

      **Build Check:**
      ```json
      {{build_check}}
      ```

      **Individual Validation Summary:**
      - Total bundles: {{individual_validation.summary.total}}
      - Passed: {{individual_validation.summary.passed}}
      - Failed: {{individual_validation.summary.failed}}
      - Warnings: {{individual_validation.summary.warnings}}

      Provide a concise approval noting:
      1. ‚úÖ Confirm all bundles load and meet quality standards
      2. ‚úÖ Confirm Python packaging is valid (if applicable)
      3. What's done well (patterns worth preserving)
      4. Any optional polish suggestions (NOT requirements - bundles are already good)

      Keep the response brief - this is the fast-track approval path.
      
      Format:
      ## ‚úÖ PASS - All Bundles Meet Quality Standards
      
      **Summary:** [1-2 sentences]
      
      **What's Done Well:**
      - [list 2-3 positive patterns]
      
      **Optional Polish (not required):**
      - [0-2 minor suggestions, or "None - repository is exemplary"]
    output: "approval_summary"
    timeout: 120

  # ============================================================================
  # PHASE 4: Repository Composition Analysis (Conditional)
  # Analyze how the pieces fit together
  # Only runs when quality_classification.requires_llm_analysis == true
  # ============================================================================

  - id: "composition-analysis"
    agent: "foundation:zen-architect"
    mode: "ANALYZE"
    condition: "{{quality_classification.requires_llm_analysis}} == true"
    depends_on: ["set-default-composition-analysis"]
    prompt: |
      Analyze the composition of this bundle repository.

      **Repository Path:** {{repo_path}}

      **Quality Classification (focus on these issues):**
      ```json
      {{quality_classification}}
      ```

      **Discovery Results:**
      ```json
      {{discovery_results}}
      ```

      **Packaging Check:**
      ```json
      {{packaging_check}}
      ```

      **Build Check:**
      ```json
      {{build_check}}
      ```

      **Individual Bundle Validation:**
      ```json
      {{individual_validation}}
      ```

      **IMPORTANT: Focus ONLY on bundles/issues with quality != "good"**
      
      Bundles classified as "good" have ALREADY PASSED. Do NOT suggest improvements for them.

      **What is NOT an Issue (do not flag these):**
      - Using /bundles/ vs /behaviors/ is a LOCATION choice, not an error
      - Missing optional files (CONTRIBUTING.md, etc.)
      - Alternative valid patterns (inline agents vs file refs)
      - Minor style differences in naming or structure
      - "Could be slightly better" for repos that meet thresholds
      - Different organizational approaches that still work
      - Not having every possible directory (only what's needed)

      **Only flag genuine issues:**
      - Bundles that fail to load (critical)
      - Broken includes/references that prevent loading
      - Orphan agents that are never used
      - Structural issues that would confuse users
      - **Python packaging errors (pyproject.toml force-includes referencing missing directories)**
      - **Build failures (hatchling/setuptools configuration issues)**

      **Reference Documentation:**
      Review these for conventions:
      - @foundation:docs/CONCEPTS.md (structural terminology)
      - @foundation:docs/BUNDLE_GUIDE.md (directory conventions, composition patterns)

      **Composition Analysis Tasks:**

      1. **Root Bundle + Behavior DRY Pattern** (RECOMMENDED, not required):
         If repo has a root bundle AND behaviors/, it's RECOMMENDED that the root include
         its own behavior for DRY composition. This is a convention for maintainability,
         not a hard requirement.

      2. **Standalone Bundle Session Configuration**:
         For each bundle in /bundles/, check if it's intended as a standalone entry point.
         If so, it needs session.orchestrator and session.context (directly OR via includes).
         If the bundle lacks session configuration, it may be intended for composition -
         in which case it should be in /behaviors/ instead.

      3. **Provider Bundle Isolation** (RECOMMENDED, not required):
         Provider configurations are typically isolated in /providers/ for reusability.
         Root bundles typically don't hardcode providers, but this is a convention for
         flexibility, not a hard requirement.

      4. **Agent Accessibility**:
         Are agents in /agents/ included by behaviors or root bundle?
         Orphan agents (not included anywhere) may indicate incomplete setup.

      5. **Namespace Consistency**:
         Do all bundles use the same namespace (from root bundle.name)?
         Mixed namespaces can cause include resolution issues.

      6. **Cross-Bundle References**:
         Do includes between bundles resolve correctly?
         Check for broken references or incorrect paths.

      7. **Python Packaging Consistency** (v2.1.0):
         If pyproject.toml exists, verify:
         - All force-include paths exist on disk
         - Directory renames are reflected in build config
         - Package data references are valid

      **Output Format:**
      For each analysis area:
      - **Finding**: What you observed
      - **Status**: GOOD | ISSUE | N/A
      - **Recommendation**: If ISSUE, how to fix
    output: "composition_analysis"
    timeout: 300
    depends_on: ["quality-classification"]

  # ============================================================================
  # PHASE 4.5: Convention Compliance (Conditional)
  # Check repo-wide conventions
  # Only runs when quality_classification.requires_llm_analysis == true
  # ============================================================================

  - id: "repo-conventions"
    agent: "foundation:zen-architect"
    mode: "REVIEW"
    condition: "{{quality_classification.requires_llm_analysis}} == true"
    depends_on: ["set-default-repo-conventions", "composition-analysis"]
    prompt: |
      Review repository-wide convention compliance.

      **Repository Path:** {{repo_path}}

      **Quality Classification:**
      ```json
      {{quality_classification}}
      ```

      **Discovery:**
      ```json
      {{discovery_results}}
      ```

      **Packaging Check:**
      ```json
      {{packaging_check}}
      ```

      **Build Check:**
      ```json
      {{build_check}}
      ```

      **Individual Validation:**
      ```json
      {{individual_validation}}
      ```

      **IMPORTANT: Focus ONLY on genuine convention violations that impact functionality**
      
      **What is NOT an Issue (do not flag these):**
      - Using .yaml vs .md for bundles (both are valid)
      - Not having every possible directory
      - Alternative valid naming styles (kebab-case, snake_case)
      - Missing optional documentation (CONTRIBUTING, etc.)
      - Different structural approaches that still work
      - "Could be slightly better" suggestions for working repos
      - Personal preferences about organization

      **Only flag genuine issues:**
      - Completely missing required files for functionality
      - Naming that breaks resolution (spaces, special chars)
      - File format mismatches (agent in .yaml instead of .md)
      - Structural issues that prevent loading
      - **pyproject.toml force-includes that reference non-existent directories**

      **Conventions to Check (Repo-Wide):**

      1. **Directory Structure**:
         - /bundle.md or /bundle.yaml at root (recommended)
         - /behaviors/ for reusable capability bundles
         - /bundles/ for standalone variant bundles
         - /providers/ for provider configurations
         - /agents/ for agent definitions
         - /context/ for shared context files
         - /docs/ for documentation
         - /modules/ for local tool modules (if any)

      2. **Naming Conventions**:
         - Behavior files: descriptive-name.yaml
         - Agent files: descriptive-name.md
         - Consistent naming style across the repo

      3. **Documentation**:
         - README.md at root
         - Agent descriptions in meta.description
         - Bundle descriptions in bundle.description

      4. **File Format Consistency**:
         - Bundles: .yaml or .md (prefer .md for root, .yaml for behaviors)
         - Agents: always .md (markdown with YAML frontmatter)

      5. **Required Files**:
         - LICENSE (for public repos)
         - At least one of: bundle.md, bundles/, behaviors/

      6. **Python Packaging** (if pyproject.toml exists):
         - force-include paths must exist on disk
         - package-data patterns should resolve
         - Build should succeed without errors

      **Read actual files as needed** to verify conventions.

      **Output Format:**
      Convention checklist with PASS/FAIL/N/A and notes.
      Only list FAIL items if they genuinely break functionality.
    output: "repo_conventions"
    timeout: 300
    depends_on: ["composition-analysis"]

  # ============================================================================
  # PHASE 5: Final Report Synthesis
  # Generates different reports based on quality_level
  # ============================================================================

  - id: "synthesize-report"
    agent: "foundation:zen-architect"
    mode: "ANALYZE"
    prompt: |
      Synthesize all validation results into a comprehensive repository validation report.

      **Repository:** {{repo_path}}

      **Quality Classification:**
      ```json
      {{quality_classification}}
      ```

      **Environment:**
      ```json
      {{env_check}}
      ```

      **Packaging Check:**
      ```json
      {{packaging_check}}
      ```

      **Build Check:**
      ```json
      {{build_check}}
      ```

      **Discovery:**
      ```json
      {{discovery_results}}
      ```

      **Individual Bundle Validation:**
      ```json
      {{individual_validation}}
      ```

      **Quick Approval Summary:**
      {{approval_summary}}

      **Composition Analysis:**
      {{composition_analysis}}

      **Repository Conventions:**
      {{repo_conventions}}

      **REPORT GENERATION RULES:**

      1. If quality_level == "good": Generate a PASS report celebrating the clean bill of health
      2. If quality_level == "polish": Generate a PASS WITH SUGGESTIONS report (optional improvements)
      3. If quality_level == "needs_work": Generate a PASS WITH WARNINGS report (should fix)
      4. If quality_level == "critical": Generate a FAIL report (must fix)

      **Verdict Selection:**
      - **‚úÖ PASS**: All bundles load and meet quality thresholds (quality_level == "good")
      - **‚úÖ PASS WITH SUGGESTIONS**: Minor polish opportunities (quality_level == "polish")
      - **‚ö†Ô∏è PASS WITH WARNINGS**: Some bundles/structure needs work (quality_level == "needs_work")
      - **‚ùå FAIL**: Critical issues found (quality_level == "critical")

      **Generate this report structure:**

      # Bundle Repository Validation Report

      ## Executive Summary
      - **Overall Verdict**: [Select from above based on quality_level]
      - **Repository**: path
      - **Bundles Found**: X total (Y root, Z behaviors, ...)
      - **Quality Breakdown**: X good, Y polish, Z needs_work, W critical
      - **Packaging**: PASS/FAIL (with note if pyproject.toml present)
      - **Issues**: X errors, Y warnings, Z suggestions

      ## Bundle Discovery
      Summary of what was found in the repository.

      ## Python Packaging Status (if applicable)
      - pyproject.toml: present/absent
      - Force-includes checked: X
      - Build check: passed/failed/skipped
      - Any packaging issues found

      ## Quality Classification Summary

      | Bundle | Category | Quality | Issues |
      |--------|----------|---------|--------|
      | name   | category | good/polish/needs_work/critical | count |

      ## Detailed Findings

      **For PASS verdict:** Highlight what's done well. Any suggestions are OPTIONAL.

      **For other verdicts:**

      ### Errors (Must Fix) - HIGH Priority
      Issues that break bundle loading or basic functionality.
      **Include any Python packaging errors here - they block installation!**

      ### Warnings (Should Fix) - MEDIUM Priority
      Structural issues or convention violations that may cause problems.

      ### Suggestions (Consider) - LOW Priority
      Quality improvements for better maintainability.

      ## Recommendations

      Prioritized list of actions with clear HIGH/MEDIUM/LOW labels.

      ## Metadata
      - Validated: [timestamp]
      - Recipe: validate-bundle-repo v2.1.0
      - Foundation: version from env_check
      - Quality Thresholds:
        - All bundles must load via BundleRegistry
        - Must have entry point (root bundle OR behaviors/bundles dirs)
        - No orphan agents (if agents/ exists, they must be included)
        - Python packaging must build successfully (if pyproject.toml present)

      Make the report actionable with clear next steps.
      
      **IMPORTANT:** If verdict is PASS, emphasize that the bundles are GOOD and any suggestions are truly optional polish, not required changes.
    output: "final_report"
    timeout: 300
    depends_on: ["quality-classification", "quick-approval", "composition-analysis", "repo-conventions", "set-default-approval-summary", "set-default-composition-analysis", "set-default-repo-conventions"]

  # ============================================================================
  # PHASE 6 (OPTIONAL): Agent Validation Integration
  # Placeholder for calling validate-agents recipe
  # Only runs if validate_agents context variable is "true"
  # ============================================================================

  # FUTURE ENHANCEMENT: Uncomment and refine when agent validation integration is desired
  # This would call the validate-agents recipe as a sub-recipe
  #
  # - id: "agent-validation-check"
  #   type: "recipe"
  #   condition: "{{validate_agents}} == true"
  #   recipe: "validate-agents.yaml"
  #   context:
  #     repo_path: "{{repo_path}}"
  #   output: "agent_validation_results"
  #   depends_on: ["synthesize-report"]
  #
  # When enabled, this step would:
  # 1. Run validate-agents.yaml on the same repo
  # 2. Capture agent quality classification
  # 3. Include agent findings in a combined report
  #
  # The parent session can control this via:
  #   context='{"repo_path": "/path/to/repo", "validate_agents": "true"}'
